{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01bb306-e92f-4666-9dc0-efb8f063fff6",
   "metadata": {},
   "source": [
    "# **CONCLUSIONES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17c56c-fe75-4bb2-94fe-0c32a6b98ba0",
   "metadata": {},
   "source": [
    "Hemos podido ver claramente que tenemos **un dataset muy desbalanceado** no llegando la clase objetivo ni al 1% del total. Al fin y al cabo esto es más común de lo que suele parecer.\n",
    "\n",
    "Como bien hemos comentado y se ha visto a lo largo del proceso de desarrollo, la métrica de accuracy no nos es suficientemente útil, ya que el **Accuracy del modelo es básicamente el numero total de predicciones correctas dividido por el número total de predicciones**. Esto hace que al tener una clase muy desbalanceada, la clase que deseamos y que tenemos interés en clasificar, que será la minoritaria, no se clasifique correctamente a pesar de tener un accuracy muy bueno.  \n",
    "\n",
    "Por ello no nos centraremos en la métrica comentada, será necesario entender las métricas **precision y recall**.  \n",
    "* **Precision**. La Precisión de una clase define cuan confiable es un modelo en responder si un punto pertenece a esa clase.  \n",
    "* **Recall**. El Recall de una clase expresa cuan bien puede el modelo detectar a esa clase.  \n",
    "\n",
    "Con estas 2 métricas podemos tener varias combinaciones en función de sus valores que nos perimitirán escoger entre los diferentes resultados.\n",
    "* **Alta precision y alto recall**: el modelo maneja perfectamente esa clase.\n",
    "* **Alta precision y bajo recall**: el modelo no detecta la clase muy bien, pero cuando lo hace es altamente confiable.\n",
    "* **Baja precisión y alto recall**: La clase detecta bien la clase pero también incluye muestras de otras clases.\n",
    "* **Baja precisión y bajo recall**: El modelo no logra clasificar la clase correctamente.\n",
    "\n",
    "Una vez conocidas las metricas que utilizaremos, definiremos el algoritmo que utilizaremos en primera instancia. Utilizaremos el algoritmo RandomForest (RF). **El Random Forest es un algoritmo de clasificación supervisado**. Este algoritmo crea un conjunto de árboles de decisión y a partir de los resultados individuales de cada uno de ellos, se realiza una predicción del comportamiento de un individuo.\n",
    "\n",
    "**Random Forest funciona así:**\n",
    "\n",
    "1. Seleccionamos k features (columnas) de las m totales (siendo k menor a m) y creamos un árbol de decisión con esas k características.\n",
    "2. Creamos n árboles variando siempre la cantidad de k features y también podríamos variar la cantidad de muestras que pasamos a esos árboles (esto es conocido como “bootstrap sample”)\n",
    "3. Tomamos cada uno de los n árboles y le pedimos que hagan una misma clasificación. Guardamos el resultado de cada árbol obteniendo n salidas.\n",
    "4. Calculamos los votos obtenidos para cada “clase” seleccionada y consideraremos a la más votada como la clasificación final de nuestro “bosque”.\n",
    "\n",
    "Debido a la problemática que tenemos del dataset debemos combinar el algoritmo seleccionado con diferentes técnicas que permitan miticar la problemática del desbalanceo. A continuación se explicarán las diferentes técnicas utilizadas en el desarrollo:\n",
    "* **Ajuste de Parámetros del modelo**: Consiste en ajustar parametros ó metricas del propio algoritmo para intentar equilibrar a la clase minoritaria penalizando a la clase mayoritaria durante el entrenamiento. Ejemplos on ajuste de peso en árboles, también en logisticregression tenemos el parámetro class_weight= “balanced” que utilizaremos en este ejemplo. No todos los algoritmos tienen estas posibilidades. En redes neuronales por ejemplo podríamos ajustar la métrica de Loss para que penalice a las clases mayoritarias.\n",
    "* **Modificar el Dataset**: podemos eliminar muestras de la clase mayoritaria para reducirlo e intentar equilibrar la situación. Tiene como “peligroso” que podemos prescindir de muestras importantes, que brindan información y por lo tanto empeorar el modelo. Entonces para seleccionar qué muestras eliminar, deberíamos seguir algún criterio. También podríamos agregar nuevas filas con los mismos valores de las clases minoritarias, por ejemplo cuadriplicar nuestras 492 filas. Pero esto no sirve demasiado y podemos llevar al modelo a caer en overfitting.  \n",
    "* **Muestras artificiales**: podemos intentar crear muestras sintéticas (no idénticas) utilizando diversos algoritmos que intentan seguir la tendencia del grupo minoritario. Según el método, podemos mejorar los resultados. Lo peligroso de crear muestras sintéticas es que podemos alterar la distribución “natural” de esa clase y confundir al modelo en su clasificación.\n",
    "* **Balanced Ensemble Methods**: Utiliza las ventajas de hacer ensamble de métodos, es decir, entrenar diversos modelos y entre todos obtener el resultado final (por ejemplo “votando”) pero se asegura de tomar muestras de entrenamiento equilibradas.\n",
    "\n",
    "Realizaremos un modleo base sobre el que comparar los resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67310640-7b8e-4ed9-93bc-e8849af53c02",
   "metadata": {},
   "source": [
    "Dentro de las diferentes técnicas para el tratamiento de datos desbalanceados, existen distintos algoritmos. En concreto se explicarán los utilizados en las tecnicas de **Muestras artificiales** y **Balanced Ensemble Methods**:\n",
    "\n",
    "1. **Muestras artificiales**:\n",
    "  * **Subsampling en la clase mayoritaria**.\n",
    "    * **RandomUnderSampler**: Submuestrear la(s) clase(s) mayoritaria(s) seleccionando muestras al azar con o sin reemplazo\n",
    "  * **Oversampling en la clase minoritaria**.\n",
    "    * **SMOTE**: Este objeto es una implementación de SMOTE - Técnica de sobremuestreo de minorías sintéticas.\n",
    "  * **Combinamos OverSampling con Subsampling**.\n",
    "    * **SMOTE & RandomUnderSampler**\n",
    "    * **SMOTE-Tomek**: Sobremuestreo usando SMOTE y limpieza usando enlaces Tomek. Combina sobremuestreo y submuestreo utilizando enlaces SMOTE y Tomek.\n",
    "    \n",
    "2. **Balanced Ensemble Methods**:\n",
    "  * **Ensamble de Modelos con Balanceo**\n",
    "    * **BalancedBaggingClassifier**: Un clasificador de ensacado con balanceo adicional. Esta implementación de Bagging es similar a la implementación de scikit-learn. Incluye un paso adicional para equilibrar el conjunto de entrenamiento en el momento de ajuste utilizando un muestreador determinado. \n",
    "    * **RUSBoostClassifier**: Submuestreo aleatorio integrado en el aprendizaje de AdaBoost. Durante el aprendizaje, el problema del equilibrio de clases se alivia mediante un submuestreo aleatorio de la muestra en cada iteración del algoritmo de refuerzo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566a832-05bc-409f-8c8d-78130a87b18c",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2251683-b290-4b8e-a24f-12caa93d8481",
   "metadata": {},
   "source": [
    "# **Resultados** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17e397-b74b-445b-be75-47f80a2575b8",
   "metadata": {},
   "source": [
    "## 1. Notebook: Modelo_1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a4bc8-47bf-4f65-a770-6447b25e5121",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 1.00 | 1.00 | 1.00 | **1.00** | 0.98 | 0.86 | **0.92** | 26 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d432fd-a96a-4db0-b0b6-dea0c55ab130",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Penalización para compensar** | -- | 0.99 | 1.00 | 1.00 | **1.00** | 0.92 | 0.87 | **0.89** | 25 |\n",
    "| Modelo 2 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.93 | 1.00 | 0.93 | **0.96** | 0.27 | 0.92 | **0.42** | 26 |\n",
    "| Modelo 3 | **Oversampling en la clase minoritaria** | SMOTE| 1.00 | 1.00 | 1.00 | **1.00** | 0.96 | 0.86 | **0.91** | 26 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 0.99 | 1.00 | 1.00 | **1.00** | 0.93 | 0.86 | **0.9** | 24 |\n",
    "| Modelo 5 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 1.00 | 1.00 | 1.00 | **1.00** | 0.96 | 0.86 | **0.91** | 27 |\n",
    "| Modelo 6 | **Ensamble de Modelos con Balanceo** | BalancedBaggingClassifier| 0.95 | 1.00 | 0.95 | **0.97** | 0.34 | 0.91 | **0.5**  | -- |\n",
    "| Modelo 7 | **Ensamble de Modelos con Balanceo** | RUSBoostClassifier| 0.97 | 1.00 | 0.98 | **0.99** | 0.5 | 0.9 | **0.64** | -- |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c242d-929c-4d0c-9a26-128869c0298b",
   "metadata": {},
   "source": [
    "Tras los resultados obtenidos y expuestos, podemos concluir que las técnicas que mejores resultados nos han proporcionado estan entre **Penalización para compensar**, **Oversampling en la clase minoritaria** y **Combinamos OverSampling con Subsampling**, (SMOTE y SMOTE-Tomek respectivamente). Los resultados de las técnicas son muy parecidos al del modelo Base.\n",
    "\n",
    "Análizando las diferentes métricas obtenidas, en primer lugar nos fijamos que todos las diferentes técnicas tienen un F1-score de la clase No Clientes muy similar entre ellas, por lo que marcará la diferencias será la clase Clientes.\n",
    "\n",
    "Observando que el modelo base y las técnicas SMOTE y SMOTE-Tomek son los que mejor F1 en la clase clientes tienen, analizaremos en detalle la precisión y recall de cada uno.\n",
    "\n",
    "Entendiendo que el objetivo del negocio es poder desarrollar una estrategia en base a un determinado grupo, lo que premiaremos es el modelo que mejor recall tenga, ya que lo que interesa es detectar bien la clase clientes. El modelo que mejor responde a esto es el que utiliza la técnica **penalizar para compensar**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a52b86-d861-4fee-92cc-7427b1e3bed9",
   "metadata": {},
   "source": [
    "## 2. Notebook: Modelo_2- PF.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccc1f4-43b8-42d3-9552-f84c96b1e732",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 1.00 | 1.00 | 1.00 | **1.00** | 0.97 | 0.76 | **0.85** | 34 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4733326-46fd-4fa6-99aa-6f0810583621",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Penalización para compensar** | -- | 0.99 | 1.00 | 1.00 | **1.00** | 0.74 | 0.79 | **0.77** | 29 |\n",
    "| Modelo 2 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.9 | 1.00 | 0.9 | **0.94** | 0.1 | 0.9 | **0.18** | 30 |\n",
    "| Modelo 3 | **Oversampling en la clase minoritaria** | SMOTE| 1.00 | 1.00 | 1.00 | **1.00** | 0.88 | 0.77 | **0.82** | 36 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 1.00 | 1.00 | 1.00 | **1.00** | 0.87 | 0.78 | **0.82** | 32 |\n",
    "| Modelo 5 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 1.00 | 1.00 | 1.00 | **1.00** | 0.89 | 0.77 | **0.82** | 35 |\n",
    "| Modelo 6 | **Ensamble de Modelos con Balanceo** | BalancedBaggingClassifier| 0.92 | 1.00 | 0.92 | **0.96** | 0.12 | 0.87 | **0.22**  | -- |\n",
    "| Modelo 7 | **Ensamble de Modelos con Balanceo** | RUSBoostClassifier| 0.93 | 1.00 | 0.93 | **0.96** | 0.13 | 0.87 | **0.23** | -- |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55616863-182a-43e3-95ba-127e59a14104",
   "metadata": {},
   "source": [
    "Tras los resultados obtenidos y expuestos, podemos concluir que las técnicas que mejores resultados nos han proporcionado estan entre **Oversampling en la clase minoritaria** y **Combinación OverSampling con Subsampling**. Los resultados de las técnicas son muy parecidos al del modelo Base.\n",
    "\n",
    "Análizando las diferentes métricas obtenidas, en primer lugar nos fijamos que todos las diferentes técnicas tienen un F1-score de la clase No Clientes muy similar entre ellas, por lo que marcará la diferencias será la clase Clientes.\n",
    "\n",
    "Observando que el modelo base y las técnicas SMOTE y las de combinación de oversampling y subsampling son los que mejor F1 en la clase clientes tienen, analizaremos en detalle la precisión y recall de cada uno.Unicamente la técnica de ensamblado de modelos con balanceo son los que peor resultado han proporcionado, en los que a F1 de la clase Clientes se refiere.\n",
    "\n",
    "Sin embargo, entendiendo que el objetivo del negocio es poder desarrollar una estrategia en base a un determinado grupo, lo que premiaremos es el modelo que mejor recall tenga, ya que lo que interesa es detectar bien la clase clientes.\n",
    "\n",
    "**En este caso preferiremos enviar ofertas a más clientes que perder clientes que si lo son**\n",
    "\n",
    "El modelo que mejor responde a esto es el que utiliza la técnica **Ensamble de Modelos con Balanceo**, en concreto un boosting, que parece que tiene mejor recall de la clase No Clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001269a5-01e9-4916-9a00-028daf13c264",
   "metadata": {},
   "source": [
    "## 3. Notebook: Modelo_2- PJ.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f02873-8188-43db-8fc4-14f2d31bf381",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 0.99 | 0.99 | 1.00 | **1.00** | 1.00 | 0.91 | **0.95** | 28 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3cffa-ffa3-4c63-b4c8-93f1c7861856",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Penalización para compensar** | -- | 0.99 | 0.99 | 1.00 | **1.00** | 1.00 | 0.91 | **0.95** | 29 |\n",
    "| Modelo 2 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.96 | 1.00 | 0.97 | **0.98** | 0.67 | 0.95 | **0.78** | 28 |\n",
    "| Modelo 3 | **Oversampling en la clase minoritaria** | SMOTE| 0.99 | 0.99 | 1.00 | **1.00** | 0.99 | 0.92 | **0.95** | 29 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 0.99 | 0.99 | 1.00 | **1.00** | 0.98 | 0.92 | **0.95** | 27 |\n",
    "| Modelo 5 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 0.99 | 0.99 | 1.00 | **1.00** | 0.99 | 0.92 | **0.95** | 30 |\n",
    "| Modelo 6 | **Ensamble de Modelos con Balanceo** | BalancedBaggingClassifier| 0.98 | 1.00 | 0.98 | **0.99** | 0.75 | 0.94 | **0.84**  | -- |\n",
    "| Modelo 7 | **Ensamble de Modelos con Balanceo** | RUSBoostClassifier| 0.98 | 1.00 | 0.98 | **0.99** | 0.81 | 0.94 | **0.87** | -- |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3a1a8-0452-47ac-8d0b-3571bf23afff",
   "metadata": {},
   "source": [
    "Tras los resultados obtenidos y expuestos, podemos concluir que las técnicas que mejores resultados nos han proporcionado estan entre **Penalización para compensar**, **Oversampling en la clase minoritaria** y **Combinamos OverSampling con Subsampling**. Los resultados de las técnicas son muy parecidos al del modelo Base.\n",
    "\n",
    "Análizando las diferentes métricas obtenidas, en primer lugar nos fijamos que todos las diferentes técnicas tienen un F1-score de la clase No Clientes muy similar entre ellas, por lo que marcará la diferencias será la clase Clientes.\n",
    "\n",
    "Observando que el modelo base y las técnicas SMOTE y SMOTE-Tomek son los que mejor F1 en la clase clientes tienen, analizaremos en detalle la precisión y recall de cada uno. Unicamente la técnica de **ensamblado de modelos con balanceo** son los que peor resultado han proporcionado, en los que a F1 de la clase Clientes se refiere. \n",
    "\n",
    "Sin embargo, entendiendo que el objetivo del negocio es poder desarrollar una estrategia en base a un determinado grupo, lo que premiaremos es el modelo que mejor recall tenga, ya que lo que interesa es detectar bien la clase clientes. \n",
    "\n",
    "El modelo que mejor responde a esto es el que utiliza la técnica **Ensamble de Modelos con Balanceo**, en concreto un boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082cb527-7e31-4d68-a5f8-057cfe7385c0",
   "metadata": {},
   "source": [
    "## 4. Notebook: Modelo_3- ALTAS.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d2a0f-b525-4f9a-99ed-c4fb9ef17741",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoAltas - Precision  | NoAltas - Recall  | NoAltas F1-score | Altas - Precision | Altas - Recall | Altas F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 0.99 | 0.99 | 1.00 | **1.00** | 0.98 | 0.81 | **0.88** | 26 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5326d-0e0d-4216-a2ba-8940be675757",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoAltas - Precision  | NoAltas - Recall  | NoAltas F1-score | Altas - Precision | Altas - Recall | Altas F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Penalización para compensar** | -- | 0.99 | 0.99 | 1.00 | **1.00** | 0.89 | 0.82 | **0.85** | 24 |\n",
    "| Modelo 2 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.91 | 1.00 | 0.91 | **0.95** | 0.24 | 0.89 | **0.38** | 24 |\n",
    "| Modelo 3 | **Oversampling en la clase minoritaria** | SMOTE| 0.99 | 0.99 | 1.00 | **1.00** | 0.92 | 0.81 | **0.86** | 26 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 0.99 | 0.99 | 1.00 | **1.00** | 0.9 | 0.81 | **0.86** | 23 |\n",
    "| Modelo 5 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 0.99 | 0.99 | 1.00 | **1.00** | 0.92 | 0.81 | **0.86** | 27 |\n",
    "| Modelo 6 | **Ensamble de Modelos con Balanceo** | BalancedBaggingClassifier| 0.94 | 1.00 | 0.94 | **0.97** | 0.32 | 0.87 | **0.47**  | -- |\n",
    "| Modelo 7 | **Ensamble de Modelos con Balanceo** | RUSBoostClassifier| 0.96 | 1.00 | 0.96 | **0.98** | 0.43 | 0.86 | **0.58** | -- |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dfcced-6665-4064-a4c3-068c86f28ab9",
   "metadata": {},
   "source": [
    "Tras los resultados obtenidos y expuestos, podemos concluir que las técnicas que mejores resultados nos han proporcionado estan entre **Penalización para compensar**, **Oversampling en la clase minoritaria** y **Combinamos OverSampling con Subsampling**, (SMOTE y SMOTE-Tomek respectivamente). Los resultados de las técnicas son muy parecidos al del modelo Base.\n",
    "\n",
    "Análizando las diferentes métricas obtenidas, en primer lugar nos fijamos que todos las diferentes técnicas tienen un F1-score de la clase No Clientes muy similar entre ellas, por lo que marcará la diferencias será la clase Clientes.\n",
    "\n",
    "Observando que el modelo base y las técnicas SMOTE y SMOTE-Tomek son los que mejor F1 en la clase clientes tienen, analizaremos en detalle la precisión y recall de cada uno.\n",
    "\n",
    "Entendiendo que el objetivo del negocio es poder desarrollar una estrategia en base a un determinado grupo, lo que premiaremos es el modelo que mejor recall tenga, ya que lo que interesa es detectar bien la clase clientes. El modelo que mejor responde a esto es el que utiliza la técnica **penalizar para compensar**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b0033-d00a-450b-a473-e870f787e228",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b3770-cde0-4ffe-b438-c096962643a1",
   "metadata": {},
   "source": [
    "## 5. Notebook: Modelo_4- XGBoost.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6178c4-741e-4337-9686-a7c74659419d",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 1.00 | 1.00 | 1.00 | **1.00** | 0.97 | 0.84 | **0.90** | 26 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457ac79-05ed-4c1c-8db2-5e6ecd856c49",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.92 | 1.00 | 0.92 | **0.96** | 0.23 | 0.92 | **0.37** | 17 |\n",
    "| Modelo 2 | **Oversampling en la clase minoritaria** | SMOTE| 0.99 | 1.00 | 1.00 | **1.00** | 0.92 | 0.85 | **0.88** | 21 |\n",
    "| Modelo 3 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 0.99 | 1.00 | 1.00 | **1.00** | 0.88 | 0.86 | **0.87** | 25 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 0.99 | 1.00 | 1.00 | **1.00** | 0.91 | 0.85 | **0.88** | 24 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cbe77b-3968-4a8d-8ee8-39d2e1c32773",
   "metadata": {},
   "source": [
    "## 6. Notebook: Modelo_5- PF - XGBoost.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0b9dc-779e-4dda-97bd-d77f6cd7dcf8",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 1.00 | 1.00 | 1.00 | **1.00** | 0.95 | 0.73 | **0.82** | 46 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e75e8-22c1-46dc-9a2f-5b97d8352226",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.87 | 1.00 | 0.87 | **0.93** | 0.08 | 0.90 | **0.15** | 40 |\n",
    "| Modelo 2 | **Oversampling en la clase minoritaria** | SMOTE| 1.00 | 1.00 | 1.00 | **1.00** | 0.84 | 0.74 | **0.79** | 42 |\n",
    "| Modelo 3 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 0.99 | 1.00 | 1.00 | **1.00** | 0.78 | 0.76 | **0.77** | 31 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 1.00 | 1.00 | 1.00 | **1.00** | 0.83 | 0.75 | **0.79** | 34 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee6f7b-26fd-4723-8a9b-e0ee672a2754",
   "metadata": {},
   "source": [
    "## 7. Notebook: Modelo_5- PJ - XGBoost.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3fc55-dceb-4ecc-b10b-64cb25943d5f",
   "metadata": {},
   "source": [
    "| Modelo | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Baseline | 0.99 | 0.99 | 1.00 | **1.00** | 0.97 | 0.93 | **0.95** | 25 |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d2304-009d-4794-9f7d-3adb421d35bb",
   "metadata": {},
   "source": [
    "| Modelo |Tecnica |Algoritmo   | Accuracy  | NoClientes - Precision  | NoClientes - Recall  | NoClientes F1-score | Clientes - Precision | Clientes - Recall | Clientes F1-score | # Variables utilizadas\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Modelo 1 | **Subsampling en la clase mayoritaria** | RandomUnderSampler | 0.94 | 1.00 | 0.94 | **0.97** | 0.52 | 0.95 | **0.67** | 17 |\n",
    "| Modelo 2 | **Oversampling en la clase minoritaria** | SMOTE| 0.99 | 0.99 | 1.00 | **1.00** | 0.97 | 0.93 | **0.95** | 18 |\n",
    "| Modelo 3 | **Combinamos OverSampling con Subsampling** | SMOTE & RandomUnderSampler | 0.99 | 0.99 | 1.00 | **1.00** | 0.94 | 0.93 | **0.93** | 23 |\n",
    "| Modelo 4 | **Combinamos OverSampling con Subsampling** | SMOTE-Tomek| 0.99 | 0.99 | 1.00 | **1.00** | 0.97 | 0.92 | **0.95** | 19 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
